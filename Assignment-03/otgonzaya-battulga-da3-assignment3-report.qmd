```{r load libraries}
#| warning: false
#| message: false
#| output: false
#| echo: false

library(readr)
library(dplyr)
library(tidyr)
library(caret)
library(randomForest)
library(glmnet)
library(knitr)
```

```{r import dataset}
#| message: false
#| output: false
#| echo: false

# Load data
df <- read_csv("data/cs_bisnode_panel.csv")
```
## Fast growing firm variable construction

```{r define fast growing firms}
#| output: false
#| echo: false

# Filter only relevant years
sales_growth <- df %>%
  filter(year %in% c(2012, 2014)) %>%
  select(comp_id, year, sales) %>%
  filter(!is.na(sales) & sales > 0) %>%
  mutate(log_sales = log(sales)) %>%
  select(comp_id, year, log_sales) %>%
  pivot_wider(names_from = year, values_from = log_sales, names_prefix = "sales_") %>%
  mutate(growth = sales_2014 - sales_2012) %>%
  filter(!is.na(growth))

# Define fast growth as top 20% 
cutoff <- quantile(sales_growth$growth, 0.8, na.rm = TRUE)

sales_growth <- sales_growth %>%
  mutate(fast_growth = ifelse(growth >= cutoff, 1, 0))
```
## Feature engineering

```{r}
#| output: false
#| echo: false

# Join labels with 2012 data
df_2012 <- df %>%
  filter(year == 2012)

df_model <- df_2012 %>%
  left_join(sales_growth %>% select(comp_id, growth, fast_growth), by = "comp_id") %>%
  filter(!is.na(fast_growth))
```

```{r}
#| output: false
#| echo: false

df_model <- df_model %>%
  mutate(
    ceo_age = year - birth_year,
    firm_age = year - founded_year,
    equity_ratio = share_eq / (fixed_assets + curr_assets + liq_assets + intang_assets),
    liquidity_ratio = liq_assets / curr_liab,
    ceo_young = ifelse(ceo_age < 40 & ceo_age > 18, 1, 0),
    foreign_mgmt = as.integer(foreign == 1),
    female_ceo = as.integer(female == 1)
  ) %>%
  mutate(across(c(ceo_age, firm_age, equity_ratio, liquidity_ratio), ~ifelse(is.infinite(.) | is.nan(.), NA, .)))
```
## Modeling dataset preparation

```{r}
#| output: false
#| echo: false
df_model <- df_model %>%
  mutate(
    region_m = factor(region_m),
    ind2 = factor(ind2),
    ind = factor(ind),
    urban_m = factor(urban_m),
    gender = factor(gender),
    origin = factor(origin)
  )
```

```{r preparing modeling data}
#| output: false
#| echo: false

set.seed(123)

# Drop missing values (or impute if you prefer later)
model_data <- df_model %>%
  select(fast_growth, sales, firm_age, ceo_age, equity_ratio, liquidity_ratio,
         foreign_mgmt, female_ceo, region_m, ind2, labor_avg) %>%
  drop_na()

# Make fast_growth a factor (for classification)
model_data$fast_growth <- factor(model_data$fast_growth, levels = c(0, 1), labels = c("no", "yes"))
```

# Task 1
## Part 1: Probability prediction 

```{r setup cross validation control}
#| output: false
#| echo: false

cv_ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,  # For ROC
  savePredictions = "final"
)
```

### Logitistic Regression  Model

```{r logit model}
#| warning: false
#| output: false
#| echo: false

logit_model <- train(fast_growth ~ ., data = model_data,
                     method = "glm",
                     family = "binomial",
                     metric = "ROC",
                     trControl = cv_ctrl)
```
### Random Forest Model

```{r random forest model}
#| output: false
#| echo: false

rf_model <- train(fast_growth ~ ., data = model_data,
                  method = "rf",
                  metric = "ROC",
                  trControl = cv_ctrl,
                  tuneLength = 3,
                  ntree = 100)
```

### LASSO Model

```{r lasso model}
#| output: false
#| echo: false

lasso_model <- train(fast_growth ~ ., data = model_data,
                     method = "glmnet",
                     metric = "ROC",
                     trControl = cv_ctrl)
```

### Model Performance Comparison 
```{r compare model performance}
#| echo: false
#| output: false

resamps <- resamples(list(Logit = logit_model, RF = rf_model, LASSO = lasso_model))
summary(resamps)

# Extract the summary
perf_summary <- summary(resamps)$statistics

# Extract the Mean values only
model_perf <- data.frame(
  ROC_AUC = perf_summary$ROC[, "Mean"],
  Sensitivity = perf_summary$Sens[, "Mean"],
  Specificity = perf_summary$Spec[, "Mean"]
)
```

```{r}
#| echo: false

kable(model_perf, digits = 4, caption = "Cross-Validated Model Performance")
```
## Part 2: Classification

```{r}
#| output: false
#| echo: false

get_model_subset <- function(data) {
  data %>%
    select(fast_growth, sales, firm_age, ceo_age, equity_ratio, liquidity_ratio,
           foreign_mgmt, female_ceo, region_m, ind2, labor_avg) %>%
    drop_na() %>%
    mutate(
      fast_growth = factor(fast_growth, levels = c(0, 1), labels = c("no", "yes")),
      region_m = factor(region_m, levels = levels(model_data$region_m)),
      ind2 = factor(ind2, levels = levels(model_data$ind2)),
      urban_m = factor(urban_m, levels = levels(model_data$urban_m))
    )
}
```
### Cost-sensitive Threshold Optimization

```{r}
evaluate_model_loss <- function(model, data, loss_FN = 10000, loss_FP = 2000) {
  probs <- predict(model, data, type = "prob")[, "yes"]
  true <- data$fast_growth
  thresholds <- seq(0.01, 0.99, by = 0.01)

  expected_loss <- sapply(thresholds, function(thresh) {
    preds <- ifelse(probs > thresh, "yes", "no")
    cm <- table(Predicted = preds, Actual = true)

    FN <- ifelse("no" %in% rownames(cm) & "yes" %in% colnames(cm), cm["no", "yes"], 0)
    FP <- ifelse("yes" %in% rownames(cm) & "no" %in% colnames(cm), cm["yes", "no"], 0)

    FN * loss_FN + FP * loss_FP
  })

  best_i <- which.min(expected_loss)
  best_thresh <- thresholds[best_i]
  final_preds <- ifelse(probs > best_thresh, "yes", "no")
  cm <- table(Predicted = final_preds, Actual = true)

  list(
    model_name = deparse(substitute(model)),
    threshold = best_thresh,
    expected_loss = expected_loss[best_i],
    confusion_matrix = cm,
    loss_vector = expected_loss,
    thresholds = thresholds
  )
}
```
