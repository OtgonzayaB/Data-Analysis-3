```{r load libraries}
#| warning: false
#| message: false
#| output: false
#| echo: false

library(readr)
library(dplyr)
library(tidyr)
library(caret)
library(randomForest)
library(glmnet)
library(knitr)
```

```{r import dataset}
#| message: false
#| output: false
#| echo: false

# Load data
df <- read_csv("data/cs_bisnode_panel.csv")
```
## Fast growing firm variable construction

```{r define fast growing firms}
#| output: false
#| echo: false

# Filter only relevant years
sales_growth <- df %>%
  filter(year %in% c(2012, 2014)) %>%
  select(comp_id, year, sales) %>%
  filter(!is.na(sales) & sales > 0) %>%
  mutate(log_sales = log(sales)) %>%
  select(comp_id, year, log_sales) %>%
  pivot_wider(names_from = year, values_from = log_sales, names_prefix = "sales_") %>%
  mutate(growth = sales_2014 - sales_2012) %>%
  filter(!is.na(growth))

# Define fast growth as top 20% 
cutoff <- quantile(sales_growth$growth, 0.8, na.rm = TRUE)

sales_growth <- sales_growth %>%
  mutate(fast_growth = ifelse(growth >= cutoff, 1, 0))
```
## Feature engineering

```{r}
#| output: false
#| echo: false

# Join labels with 2012 data
df_2012 <- df %>%
  filter(year == 2012)

df_model <- df_2012 %>%
  left_join(sales_growth %>% select(comp_id, growth, fast_growth), by = "comp_id") %>%
  filter(!is.na(fast_growth))
```

```{r}
#| output: false
#| echo: false

df_model <- df_model %>%
  mutate(
    ceo_age = year - birth_year,
    firm_age = year - founded_year,
    equity_ratio = share_eq / (fixed_assets + curr_assets + liq_assets + intang_assets),
    liquidity_ratio = liq_assets / curr_liab,
    ceo_young = ifelse(ceo_age < 40 & ceo_age > 18, 1, 0),
    foreign_mgmt = as.integer(foreign == 1),
    female_ceo = as.integer(female == 1)
  ) %>%
  mutate(across(c(ceo_age, firm_age, equity_ratio, liquidity_ratio), ~ifelse(is.infinite(.) | is.nan(.), NA, .)))
```
## Modeling dataset preparation

```{r}
#| output: false
#| echo: false
df_model <- df_model %>%
  mutate(
    region_m = factor(region_m),
    ind2 = factor(ind2),
    ind = factor(ind),
    urban_m = factor(urban_m),
    gender = factor(gender),
    origin = factor(origin)
  )
```

```{r preparing modeling data}
#| output: false
#| echo: false

set.seed(123)

# Drop missing values (or impute if you prefer later)
model_data <- df_model %>%
  select(fast_growth, sales, firm_age, ceo_age, equity_ratio, liquidity_ratio,
         foreign_mgmt, female_ceo, region_m, ind2, labor_avg) %>%
  drop_na()

# Make fast_growth a factor (for classification)
model_data$fast_growth <- factor(model_data$fast_growth, levels = c(0, 1), labels = c("no", "yes"))
```

# Task 1
## Part 1: Probability prediction 

```{r setup cross validation control}
#| output: false
#| echo: false

cv_ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,  # For ROC
  savePredictions = "final"
)
```

### Logitistic Regression  Model

```{r logit model}
#| warning: false
#| output: false
#| echo: false

logit_model <- train(fast_growth ~ ., data = model_data,
                     method = "glm",
                     family = "binomial",
                     metric = "ROC",
                     trControl = cv_ctrl)
```
### Random Forest Model

```{r random forest model}
#| output: false
#| echo: false

rf_model <- train(fast_growth ~ ., data = model_data,
                  method = "rf",
                  metric = "ROC",
                  trControl = cv_ctrl,
                  tuneLength = 3,
                  ntree = 100)
```

### LASSO Model

```{r lasso model}
#| output: false
#| echo: false

lasso_model <- train(fast_growth ~ ., data = model_data,
                     method = "glmnet",
                     metric = "ROC",
                     trControl = cv_ctrl)
```

### Model Performance Comparison 
```{r compare model performance}
#| echo: false
#| output: false

resamps <- resamples(list(Logit = logit_model, RF = rf_model, LASSO = lasso_model))
summary(resamps)

# Extract the summary
perf_summary <- summary(resamps)$statistics

# Extract the Mean values only
model_perf <- data.frame(
  ROC_AUC = perf_summary$ROC[, "Mean"],
  Sensitivity = perf_summary$Sens[, "Mean"],
  Specificity = perf_summary$Spec[, "Mean"]
)
```

```{r}
#| echo: false

kable(model_perf, digits = 4, caption = "Cross-Validated Model Performance")
```
## Part 2: Classification

```{r}
#| output: false
#| echo: false

get_model_subset <- function(data) {
  data %>%
    select(fast_growth, sales, firm_age, ceo_age, equity_ratio, liquidity_ratio,
           foreign_mgmt, female_ceo, region_m, ind2, labor_avg) %>%
    drop_na() %>%
    mutate(
      fast_growth = factor(fast_growth, levels = c(0, 1), labels = c("no", "yes")),
      region_m = factor(region_m, levels = levels(model_data$region_m)),
      ind2 = factor(ind2, levels = levels(model_data$ind2)),
      urban_m = factor(urban_m, levels = levels(model_data$urban_m))
    )
}
```
### Cost-sensitive Threshold Optimization

```{r}
evaluate_model_loss <- function(model, data, loss_FN = 10000, loss_FP = 2000) {
  probs <- predict(model, data, type = "prob")[, "yes"]
  true <- data$fast_growth
  thresholds <- seq(0.01, 0.99, by = 0.01)

  expected_loss <- sapply(thresholds, function(thresh) {
    preds <- ifelse(probs > thresh, "yes", "no")
    cm <- table(Predicted = preds, Actual = true)

    FN <- ifelse("no" %in% rownames(cm) & "yes" %in% colnames(cm), cm["no", "yes"], 0)
    FP <- ifelse("yes" %in% rownames(cm) & "no" %in% colnames(cm), cm["yes", "no"], 0)

    FN * loss_FN + FP * loss_FP
  })

  best_i <- which.min(expected_loss)
  best_thresh <- thresholds[best_i]
  final_preds <- ifelse(probs > best_thresh, "yes", "no")
  cm <- table(Predicted = final_preds, Actual = true)

  list(
    model_name = deparse(substitute(model)),
    threshold = best_thresh,
    expected_loss = expected_loss[best_i],
    confusion_matrix = cm,
    loss_vector = expected_loss,
    thresholds = thresholds
  )
}
```
```{r expected loss evaluation across models}
#| output: false
#| echo: false
#| warning: false

logit_results <- evaluate_model_loss(logit_model, model_data)
rf_results <- evaluate_model_loss(rf_model, model_data)
lasso_results <- evaluate_model_loss(lasso_model, model_data)
```
```{r}
#| echo: false

plot(rf_results$thresholds, rf_results$loss_vector, type = "l", col = "darkgreen", lwd = 2,
     ylim = range(c(rf_results$loss_vector, logit_results$loss_vector, lasso_results$loss_vector)),
     xlab = "Threshold", ylab = "Expected Loss", main = "Expected Loss vs Threshold")

lines(logit_results$thresholds, logit_results$loss_vector, col = "blue", lwd = 2)
lines(lasso_results$thresholds, lasso_results$loss_vector, col = "red", lwd = 2)
legend("topright", legend = c("Random Forest", "Logit", "LASSO"),
       col = c("darkgreen", "blue", "red"), lwd = 2)
```
## Part 3: Discussion of results

### Confusion Matrix of the Models

```{r}
#| echo: false

# Convert confusion matrices to data frames 
logit_cm <- as.data.frame.matrix(logit_results$confusion_matrix)
rf_cm <- as.data.frame.matrix(rf_results$confusion_matrix)
lasso_cm <- as.data.frame.matrix(lasso_results$confusion_matrix)

# Add model labels and restructure each confusion matrix
format_cm <- function(cm, model_name) {
  cm_df <- as.data.frame.matrix(cm)
  cm_df$Actual <- rownames(cm_df)
  cm_df$Model <- model_name
  cm_df <- cm_df[, c("Model", "Actual", "no", "yes")]
  colnames(cm_df) <- c("Model", "Actual", "Predicted: No", "Predicted: Yes")
  return(cm_df)
}

# Format and bind all three
logit_combined <- format_cm(logit_cm, "Logit")
rf_combined <- format_cm(rf_cm, "Random Forest")
lasso_combined <- format_cm(lasso_cm, "LASSO")

combined_cm <- bind_rows(logit_combined, rf_combined, lasso_combined)

# Display as one nice table
kable(combined_cm, caption = "Confusion Matrices at Optimal Thresholds (All Models)", row.names = FALSE)
```
### Expected Loss Comparison
```{r}
#| echo: false

loss_summary <- data.frame(
  Model = c("Logit", "Random Forest", "LASSO"),
  Threshold = c(logit_results$threshold, rf_results$threshold, lasso_results$threshold),
  Expected_Loss = c(logit_results$expected_loss, rf_results$expected_loss, lasso_results$expected_loss)
)

kable(loss_summary, digits = 4, caption = "Expected Loss at Optimal Thresholds")
```
