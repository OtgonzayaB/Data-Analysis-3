---
title: "Assignment 2"
author: "Otgonzaya Battulga"
date: "2025-03-30"
format: html
editor: visual
---
# Building a Prediction Model on House Prices.

In this report, I have developed a pricing model to support the operation of a chain of Airbnb properties by building and evaluating machine learning models that predict listing prices based on property characteristics, host attributes, amenities, and location.

The core dataset used is the **Q3 2024 Airbnb listings for Florida**, sourced from **Inside Airbnb**. This dataset contains over 16,000 observations, providing a comprehensive snapshot of the Florida short-term rental market. Extensive data wrangling was performed, including the extraction of key amenities, handling of missing values, and transformation of categorical variables into model ready features.

**Five predictive models were developed and compared:**

- Ordinary Least Squares (OLS)
- LASSO Regression
- Random Forest
- XGBoost
- CART

Model performance was evaluated based on predictive accuracy (RMSE and R^2) and training time, summarized in a horserace table. The best-performing models, Random Forest and XGBoost were further analyzed to explore feature importance and identify key price drivers.

**To test the validity and generalizability of the models, two additional datasets were introduced:**

- A later snapshot from the same region: Florida Q4 2024
- A different market within the U.S.: Denver Q4 2024

These datasets were used to evaluate how well the models perform across time and geographic location, providing insights into their robustness and potential for wider deployment across an Airbnb portfolio.

```{r loading libraries}
#| output: false
#| echo: false
#| message: false
#| warning: false

library(readxl)
library(tidyverse)
library(caret)
library(glmnet)
library(randomForest)
library(xgboost)
library(e1071)
library(Metrics)
library(rpart)
library(rpart.plot)
library(dplyr)
library(ggplot2)
library(knitr)
library(MetBrewer)
library(scales)
library(kableExtra)
```

```{r importing the dataset}
#| echo: false
#| warning: false

# Set the path to your dataset
file_path <- "data/florida-q3-listings.xlsx"

# Read the Excel file
df <- read_excel(file_path)
```

```{r see column names}
#| output: false
#| echo: false

names(df)
```

# Part 1. Modelling

First, I have looked at the column names and chosen the attributes and amenities I want to use to build the price model. I selected variables that are most likely to influence listing prices, including listing-level characteristics (number of bedrooms, bathrooms, accommodates etc), host attributes (superhost status, identity verification etc), geographic information (latitude, longitude, and neighbourhood etc), and key amenities such as WiFi, kitchen, pool, and parking.

## 1. Data Wrangling

```{r}
#| output: false
#| warning: false

# Making sure price is numeric and has valid values
df <- df %>%
  mutate(price = as.numeric(gsub("[$,]", "", price))) %>%
  filter(!is.na(price)) %>%
  filter(price > 20 & price < 1000)

# Clean up key columns
df_model <- df %>%
  mutate(
    host_is_superhost = ifelse(host_is_superhost == "t", 1, 0),
    host_identity_verified = ifelse(host_identity_verified == "t", 1, 0),
    host_has_profile_pic = ifelse(host_has_profile_pic == "t", 1, 0),
    host_response_rate = as.numeric(gsub("%", "", host_response_rate)),
    host_acceptance_rate = as.numeric(gsub("%", "", host_acceptance_rate)),
    latitude = as.numeric(latitude),
    longitude = as.numeric(longitude)
  )
```

The price column was first cleaned by removing dollar signs and commas, and filtered to exclude extreme outliers (keeping prices between $20 and $1000). Boolean features such as host_is_superhost, host_identity_verified, and host_has_profile_pic were converted from text to binary (1/0) format. Similarly, percentage-based features like host_response_rate and host_acceptance_rate were converted to numeric.

```{r}
# Impute missing values for numerical columns
df_model <- df_model %>%
  mutate(
    bedrooms = ifelse(is.na(bedrooms), median(bedrooms, na.rm = TRUE), bedrooms),
    beds = ifelse(is.na(beds), median(beds, na.rm = TRUE), beds),
    bathrooms = ifelse(is.na(bathrooms), median(bathrooms, na.rm = TRUE), bathrooms),
    host_response_rate = ifelse(is.na(host_response_rate), median(host_response_rate, na.rm = TRUE), host_response_rate),
    host_acceptance_rate = ifelse(is.na(host_acceptance_rate), median(host_acceptance_rate, na.rm = TRUE), host_acceptance_rate),
    host_listings_count = ifelse(is.na(host_listings_count), median(host_listings_count, na.rm = TRUE), host_listings_count)
  )

# Parse amenities into binary features
df_model <- df_model %>%
  mutate(
    has_wifi = as.numeric(grepl("Wifi", amenities)),
    has_kitchen = as.numeric(grepl("Kitchen", amenities)),
    has_pool = as.numeric(grepl("Pool", amenities)),
    has_aircon = as.numeric(grepl("Air conditioning", amenities)),
    has_parking = as.numeric(grepl("Free parking", amenities)),
    has_tv = as.numeric(grepl("TV", amenities)),
    has_hot_tub = as.numeric(grepl("Hot tub", amenities)),
    has_washer = as.numeric(grepl("Washer", amenities)),
    has_dryer = as.numeric(grepl("Dryer", amenities))
  )
```

To handle missing data, I used median imputation for numerical fields such as bedrooms, bathrooms, beds, and the host-related response and acceptance rates. For the amenities, I used regular expressions to create binary indicator variables based on whether a listing includes features like "Wifi", "Kitchen", or "Pool" in its amenities string.

```{r}
#| output: false
#| warning: false

# Select relevant columns
df_model <- df_model %>%
  select(price, accommodates, bedrooms, beds, bathrooms,
         host_is_superhost, host_identity_verified, host_has_profile_pic,
         host_response_rate, host_acceptance_rate, host_listings_count,
         latitude, longitude, neighbourhood_cleansed,
         property_type, room_type,
         starts_with("has_")) %>%
  drop_na()

# Convert categorical vars to numeric
df_model <- df_model %>%
  mutate(across(c(property_type, room_type, neighbourhood_cleansed), as.factor)) %>%
  mutate(across(c(property_type, room_type, neighbourhood_cleansed), ~ as.numeric(as.factor(.x))))

# Final check
glimpse(df_model)
```

Finally, I converted categorical variables (property_type, room_type, and neighbourhood_cleansed) to numerical factors and removed any constant or missing-value-only columns to ensure compatibility with modeling.

## 2. Building Predictive Models

The cleaned and feature-engineered dataset was then split into training and testing sets, with 80% of the data used for model training and 20% for evaluation. Constant columns and those with only a single unique value were removed to prevent issues during model fitting.

```{r train-test split}
set.seed(123)
trainIndex <- createDataPartition(df_model$price, p = 0.8, list = FALSE)
train <- df_model[trainIndex, ]
test  <- df_model[-trainIndex, ]

# Separate features and target
X_train <- train %>% select(-price)
y_train <- train$price
X_test <- test %>% select(-price)
y_test <- test$price

# Remove columns with only 1 unique value
X_train <- X_train[, sapply(X_train, function(col) length(unique(col)) > 1)]
X_test <- X_test[, colnames(X_train)]  # Match test columns to training set
```

